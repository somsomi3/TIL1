# AI란?

## AI를 왜 배워야 할까?
: 오늘날 우리는 인공지능 시대에 살고 있고, AI는 다양한 산업 분야에서 여러가지 역할을 하며, 우리의 일상생활을 변화시키고 있다.

: 제조분야: 생산라인에서 제품의 불량을 시시간으로 검출하여 생산성 향상

, 물류분야: 택배 박스의 주소를 분석하고 지역에 따라 자동 분류하여 효율성 증대

, 의료분야: 의료 이미지를 분석하여 조기진단하고 신약 개발

## 개발자에게 AI가 중요한 이유는?

1. 코드 생산성 높임
: 코드의 자동완성, 테스트,. 디버깅등 반복적인 작업을 자동화하여 개발시간을 단축, 휴먼에러 줄임

2. AI소통 능력 up
AI모델의 특징과 한계등 AI이해도를 기반으로 특정 상황과 요구사항을 명확히 지시하여 원하는 응답을 빠륵 정확히 얻음

3. AI문제 해결 역량 up
: ChatGPT API, 오픈소스 LLM등을 활용하여 복잡한 문제를 효과적으로 해경하고,
혁신 적인 아이디어를 실현함.

4. 커리어 경쟁력 up
다양한 AI직무와 협업을 통해 현업엣 다룰수 잇는 기술분야 개인의 커리어 경쟁력 향상

+ AI Foundation 모델 


# 목차
## 01. AI 기초 이론: 인공지능 기본 개념, GPT 역사, AI트렌드 등
## 02. AI 툴 활용: Techable Machine 을 활용한 간단한 AI모델 제작
## 03. AI 문제 해결 아이디어 톤: 팀별 아이디어 기획, 모델 제작 및 발표
## 04. AI 가로세로 낱말 퀴즈: 학습내용 복습


## 01. AI 기초 이론: 인공지능 기본 개념, GPT 역사, AI트렌드 등

1. Adapting to the rise of Generative AI
  - 6년내 업무자동화
  - 
  - 

2. ai기술의 적용
  Cloud Service Provider
  Medicine 
  Media& Entertainment
  Security & Defence
  Autonomous Machines

3. 미국에서는 일상적인 자율주행
  - 자율주행기술이 5단계로 나뉘다.
  1. 단순히 운전자지원: 차선이탈에 대한 경고(차선유지보조)
  2. 부분 자동화: 차선에 따라 자동으로 움직이고, 앞차와의 거리유지(smart 크루져 )
  3. 조건부 자동화: 고속도로와 같은 단순한 것에서 자율주행
  4. 고도 자동화: 도시에서 자율주행
  5. 완전 자율화: 운전자가 필요없을 정도로 자율적으로 운전함.

  - 자율주행 자동차
  - 모방학습을 통해 집안일을 해주는 로봇(모바일 알로하.)
  

ai
1. 첫번째 관점:  AI가 사람의 지능을 모사하고 있다.

2. 2번째 관점: 머신러닝은 수많은 데이터로 학습을 해서 반지름을 구할 수 있게 된다.

->현재 AI 기술의 한계: 학습 데이터 범위내에서만 추론이 가능함.
->> 이러한 한계를 극복하기 위해서, LLM대규모언어모델을 통해 학습 시킴.

-머신러닝 vs 딥러닝
: 사람이 개입하는 정도가 차이가남.
: 사람이 데이터의 특징을 선별해주는, 데이터 전처리 작업을 머신러닝이 많이 함.

: 요새 나오는 딥러닝은. 사람의 개입이 적고, 직접 많은 데이터를 학습하여, 데이터를 잘 파악할 수 있음.


- 딥러닝 모델은, 애매한 데이터(suv인지, 세단인지)를 구별하기 어렵다.
이러한 데이터들이 딥러닝의 성능을 향상시키는 중요한 모델이다. 

-머신러닝 알고리즘 중 하나가 딥러닝.
: 인공신경망을 기준으로 여러층의 신경망을 쌓아서 학습하는 모델

-AI시스템: 하드웨어(GPU), 네트워크 구조들, 데이터 자체, 인터페이스(챗 gpt같은 것들은 우리에게 왜부로 시스템을 제공 중이다.)

- 1950년대에 이미 만들어진 신경망!
: Perceptron 
사람의 신경망을 묘사한 모델.(뉴런 시냅스 관련)

: 신호가 역치값 이상일때만 전달되게끔,
활성함수를 구현한다.

: 퍼셉트론의 활성화 함수: 계산함수로 이루어짐
  : 신호가 역치 이상이면, 값을 다른 뉴련에 전달하는 것을 모사하기 위해 활성화 함수로 계단 함수(Step function)을 활용
  특정값(Threshold)
  
  : 단순한 덧셈과 곱셈으로 이루어진 활성화 함수
  f(x0w0 + x1w1 + x2w2 + x3w3 +b)

  : 뉴런이 하나가 아니고 여러개가 있어서, 복잡한 것을 구현가능.

: 퍼셉 트론을 좀더 응용해서 만든것이
LeNet, AlexNet

: 합성곱 신경망(CNN: Convolution Neural Networks)


[2]

- 이미지 픽셀 정보를 하나씩 일렬로 펴서 넣었을때 문제점?
: 전체의 정보를 파악하기 어렵다. 
: 그래서 이것을 수정한 것이, 합성곱 신경망.
: 패치 모델을 만든다.

: 필터를 사용한다.

: 3차원의 이미지 데이터-> 필터3개 ->output
( R, G, V )

-Pooling Layer
  : 큰 이미지를 처리하는 부담을 줄이기 위해, 중요한 정보로 요약하고 불필요한 세부 사항은 생략.
  : 이것은 가장 큰값, 평균값을 가져오기때문에, 딥러닝을 사용할 필요없음.

  : 이미지를 겹쳐서 보는 것이 아니라, 나눠서 본다. 

  : 단점: 나머지 정보들이 소실됨. 세부적인 특징을 버리므로, 현대 딥러닝에서는 pooling을 잘 안씀..


: 전통적인 머신러닝 알고리즘은 학습되는 데이터 사이즈를 키우고 모델을 복잡하게 할수록 성능이 늘어나긴 하지만, 한계가 있었다. 
NN에 와서는 모델사이즈를 키우고, 데이트를 많이 줄수록 성능이 올라가는 것을 발견.
따라서,  전통적인 알고리즘보다, Neural networks가 좋은 이유가 된다. 

AI를 학습하기 위해서 필요한 4가지.
key components of deep learning
- Data: 모델이 학습할 데이터
- Model: 입력 데이터를 우리가 원하는 출력으로 변환해 주는 함수
- Loss function : 모델의 출력을 통해 모델이 잘하는지 못하는지 판단해 수치화 해주는 함수(매핑)
- Algorithm:  loss를 줄여주기 위해 모델(파라미터)을 업데이터 하는 방법

min err{Label, f(data)}

AI디자인하는 방법
빅 데이터 , 모델, Loss(Reward)

1. Data

- 모든 인공지능의 기본은 분류이다.
Classification: 고양이 class를 판단.
Detection: 
Segmentation: 각 필셀별로 라벨이 있다. 고양이인지 땅인지를 구별하는 것
etc.: 각 문제정보에 맞는 데이트가 필요.

2. Model
: 딥러닝 알고리즘은 퍼셉트론으로 시작함.
퍼셉트론이란?
: 각입력값에 대한 가중치가 존재할때,
두 값을 곱한 wixi벡터의 합으로 구성된 모델
: 즉, 선형 결합 관계에 있는 가중치로 구성된 모델
: 활성화 함수를 통해 특정 임계값을 초과하는지를 기준으로 0 혹은 1의 값으로 결과 y를 출력

: 벡터 간의 내적.

: 페셉 트론의 출력은, w의 값의 분포와  x의 값의 분포가 유사할때, 출력값이 커진다.
 
즉, 입력 x가 w와 유사한 분포를 보일때, 출력이 커진다.
w는 핉터. 즉  필터에 맞는 입력이어야 출력값이 커진다.

; x와 w를 내적했을때, 비슷해야 출력값이 커지는 벡터의 내적!!

활성화 함수는 계단보다는 요새는 Relu함수를 많이 쓴다.

b: 활성화 정도를 조정해 준다.

- 선형모델(단층 퍼셉트론)의 한계
: XOR연산과 같은 복잡한 관계를 모델로 나타낼 수없음.
: 즉, 현실세계에 존재하는 데이터들의 복잡한 관계를 충분히 표현할 수 없음/

따라서,. 
 - 다층 퍼셉트론으로
    - 입력 레이어와 출력레이어만 존재하는 단일 퍼셉트론에 은닉층이라는 중간 레이어 추가
    - 즉, 여러 개의 레이어를 쌓음으로써 단일 퍼셉트론으로 표현할 수 없느 복잡한 연산을 수행 할 수 있음.

자연어 처리:
Transformer배워라


- Loss 함수
: 손실 함수
모델의, 출력값과 실제 데이터의 정답 사이의 오차를 계산하는 함수
AI모델을 학습한다는 것은 주어진 데이터에 대한 정답에 근사한 예측을 할 수 있는 모델을 만드는 것.
즉, 손실을 최대한 작은 값으로 줄이는 것이 AI 모델 학습의 목표


  - 회귀문제: 어떠한 값을 예측하는 문제
  범주가 안닌 연속적인 수치를 예측하는 문제
  주식값 예측, 판매량 예측
  Regression Task
  MSE사용( 오차 함수)
  MAE: mean absolute error
  : 오차에 절댓값을 씌운것.
  - 분류 문제: 
  주어진 데이터가 어떤 범주에 속하는지 판단하는 테스크
  강아지 인지 고양이인지, 스팸인지아닌지
  Classification Task
    - 로짓과 확률값
      로짓: 표준화  되지 않은 날 것 그대로의 모델 예측값
      확률: 로짓에 추가 연산을 가하여 [0, 1]사이의 확률값으로 나타낸 예측값.

- Cross entropy : 분류에 쓰이는 가장 대표적인 손실 함수
: 이진분류

- 다중분류: multti-class classification
: 출력값이 여러개.


-로스를 통해 가중치업데이트 하기위해서
Gradient descent가 많이 쓰인다.
: loss의 편미분은 하나의 파라미터가 loss에 미치는 영향을 알려줌.
: 로스에 대한 가중치별 기울기 값을 구한다.

: Backpropagantion: 모델의 가중치(Weight)업데이트

: 학습률 learning rate 

: learning rate Scheduler: 학습도중 학습률을 동적으로 조정