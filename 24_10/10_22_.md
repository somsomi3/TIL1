# 자바스크립트 02
## 데이터 타입
### 원시 자료형

## 연산자

## 조건문

## 반복문
### for .. in
### for ... of
### for ... in 과 for ... of

## 참고
### NaN 예시
### null & undefined

------------------

## 데이터 타입
- 원시자료형
  : Number, String, Boolean, null, undefined
  : 변수에 갑이 직접 저장되는 자료형(불견, 값이 복사)

- 참조 자료형
  : Objects=자료형으로셔의 객체 하나만 존재하는데, 객체안에( Object(:데이터 타입의 객체), Array, Function이라는 3가지 자료형이 존재한다. )
  : 객체에 주소가 저장되는 자료형() 가변, 주소가 복사)

### 원시 자료형
예시: 변수가 할당될때 값이 복사, 변수간에 서로영향을 미치지 않음.
 
 원본을 바꾸지 않는다.


참조자료형 예시: 객체를 생성하면, 객체의 메모리 주소를 변수에 할당
변수간에 서로 영향을 미침

- 원시 자료형의 종류
- Number, String, Boolean, null, undefined

- Number:정수또는 실수형을 표현하는 자료형
  : NaN 연산의 결과로 부터 나누는것으로,. 숫자/문자= NaN으로 나온다. 즉, 숫자가 아니다라는 뜻.

- String: 텍스트를 표현
  : + 연산자를 사용해 문자열 끼리 결합. 뺄셈, 곱셈, 나눗셈 불가능

  : Template literals(템플릿 리터럴)
  - 내장된 표현식을 허용하는 문자열 작성 방식
  - Backtick(``)을 이용하며, 여러줄에 걸쳐 문자열을 정의 할 수도 있고, 자바스크립트의 변수를 문자열 안에 바로 연결 할 수 있음.

- 자바 스크립트에서 값이 없음을 표현하는 null 과 undefined
  - null: 프로그래머가 의도적으로 값이 없음을 표현할때
  - undefined:  

- Boolean: true, false(소문자)
  : 조건문 또는 반복문에서  Boolean 이 아닌 데이터 타입을 자동 형변환 규칙에 따라 'true' 또는 'false'

  : 자동 형변환 조건

  데이터 타입
  undefined
  null

## 연산자
- 할당 연산자
  : 오른쪽에 있는 피연산자를 
  : 단축연산자 지원

- 증가 연산자('++')
  : 할당, 이후에 x에 +1을 함.

  : 더하고 할당

- 감소연산자
  : 피연산자를 감소시키고, 

  : 예시 99증감연산자의 예시

- 비교연산자

- 동등 연산자(==) ->암묵적으로 변환해 버리기에 이것은 추천하지 않는 방법
  :두 연산자가 같은 것으로 평가되는지 비교 후boolean
  : 비교를 할때, 한쪽을 암묵적 변환을 시도한다. 그후 같으면 같은거다.

  : [1] == 1
  동등연산자로는 ture가 나온다. 객체와 원시자료형을 비교할때, 객체를 원시자료형으로 바꿔서 비교해 버린다.. 이것도 true이다. 
  왼쪽 오른쪽은 중요하지않고, 배부적 규칙이 있다
    - 문자열, 숫자비교는 문자열-> 숫자
    - 정수, 불리언 -> 불리언을 숫자로 바꾼다,


- 일치 연산자(===): 엄격한 비교
  : 두 피연산자의 값과 타입이 모두 같은 경우, true를 반환
  : 같은 객체를 
  : 엄격한 비교가 이루어지며, 암묵적 타입 변환이 발생하지 않음.

- 논리연산자
  - and
  - or
  - not 
  - 단축 평가 지원
  

## 조건문
  - if : 조건 표현식
```
실습 02-03
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Document</title>
</head>

<body>
  <script>
    const name = 'customer'

    if (nama === 'admin'){
      console.log('관리자님 안녕')

    } else if(name === 'customer') {
      console.log('고객님 안녕')
    } else{
      console.log(`반갑습니다. ${name}님`)
    }

  </script>
</body>

</html>

```
- 삼항 연산자
  - condition
  - expression1
  - expression2

- 삼항연산자 예시
  : 간단한 조건부 로직을 간결하게 표현할때 유용
  -> 복잡한 로직이나 대다수의 경우에는 가독성이 떨어질 수 있으므로,.
  적절한 상황에서만 사용할 것.

## 반복문
- while, for, for ...in , for ... of

- while: 조건문이 참이면 문장을 계속해서 수행
```
실습 05
    // while
    let i = 0

    while (i<6) {
      console.log(i)
      i+=1
    }

![alt text](image-21.png)

```

- for :특정한 조건이 거짓으로 판별될때까지 반복
  : 초기문, 조건문, 증가문
```
실습 05 


```
### for .. in
: 객체(딕셔너리형태의 {키:값}으로 되어있는 객체. oop에서의 객체가 아님)
의 열거 가능한 속성(property)에 대해 반복;; 객체는 순서가 없다. 그래서 열거라 표현함.
```
실습05 에 for .. in 
    // for...in
    const object = {
      a: 'apple',
      b: 'banana'
    }

    for (const property in object){
      console.log(property)
      console.log(object[property])

    }


```
![alt text](image-22.png)

### for ... of
: 반복 가능한 객체(oop에서의 객체)(배열,문자열 등)에 대해 반복

```
실습
    // for...of
    const numbers = [0, 1, 2, 3]

    for (const number of numbers) {
      console.log(number)
    }

    const myStr = 'apple'




    //  문자열도 반복 가능한 객체이다.
    const myStr = 'apple'

    for (const char of myStr){
      console.log(char)
    }

```
![alt text](image-23.png)
![alt text](image-24.png)

![alt text](image-25.png)


### for ... in 과 for ... of
: 배열을 for ... in 으로 반복하였더니, a b c 가 나오지 않고, 0 1 2 가 나옴.
for ... in:: 객체(딕셔너리형태의 {키:값}으로 되어있는 객체. oop에서의 객체가 아님)
의 열거 가능한 속성
=>배열이 키값형태가 아닌데... 왜 속성이 있지?? 
    const numbers = [0, 1, 2, 3]
도 내부적으로 는
  {
    0: 0,
    1: 1,

  }
-> 이런 식으로 생겻다. 내부적으로는 순서가 부여되어서 생긴 것이다. 
그래서 앞에 잇는 0, 1인 속성값이 출력되는 것이다. 


- for ... of
  :반복가능한 객체에서 쓴다. 반복가능하다는 것은 순서가 존재한다는 것.
  - Array
    a 는 엄연히 0번째에 존재하는 것.
  - Object 는 순서가 없어서, 반복가능하지 않음.
    즉. dictionary도 순서가 없음. 그래서 for ... of가 오류가 뜬다.

  - for .. in은 객체(Object) 전용
  - for ... of은 Array(배열), 혹은 문자열 처럼 반복가능한 객체들 
         => : 배열을 for ... in 으로 반복하였더니, a b c 가 나오지 않고, 0 1 2 가 나옴. => 에러는 안나서 쓸수는 있지만, 권장하지 않음.

- 배열 반복과 for ... in 
  : 객체 관점에서의 배열의 인덱스는 "상수 이름을 가진 열거 가능한 속성"
  : for ... in 은 상수가 아닌 이름과 속성을 포함한 열거가능한 모든 속성을 반환
  => 배열에서는 for문, for ... of를 사용**** 중요함.
  : 객체 관점에서 배열의 인덱스는 정수 이름을 가진 속성이기때문에 인덱스가 출력됨( 순서 보장 X )

  - 반복문 사용 시 const 사용 여부
    - for 문: for 문에서 const를 사용하면 안되는 이유: 재할당이 되어버림;
      반복을 돌면서 i++하는데 증가를 하면서 재할당이 되어버리므로
      쓰면안됨.  

    - for ... in, for ...of 
      : 재할당이 아니라, 매 반복마다 다른 속성 이름이 변수에 지정되는 것이므로.
      const를 사용해도 에러가 발생하지 않음
      : 단, const특징에 따라, 블록 내부에서 변수를 수정할 수 없음.
      : const 만 써야하니? 아니! 반복문 안에서 변수의 값을 바꿔야하면 let을 쓰면 된다. 
      ```
            // for...of
      const numbers = [0, 1, 2, 3]

      for (const number of numbers) {
        console.log(number)
        number의 값을 변경하는 시도 안된다. 엄연히 const number 이기 때문이다. 
        let a = number + 10 =-> 이거는 핈기실수 . 안되는거 아님.
      }
      ```
- 반복문 종합
- 키워드 특징 스코프

## 참고
### NaN 예시
1. 숫자로서 읽을 수 없음(Number(undefined))
2. 결과가 허수인 수학 계산식(Math.sqrt(-1))
3. 피연산자가 NaN (7** NaN)
4. 정의 할 수 없는 계산식(0*Infinity)
5. 문자열을 포함하면서 덧셈이 아닌 계산식('가'/ 3)

### null & undefined
: 값이 없음에 대한 표현이 null과 undefined 2가지인 이유(결국은 설계이슈이다.)
1. 역사적 맥락 => 초기버전의 설계 이슈
   -JavaScript가 

2. null 타입이 "object"인 이유 => 이것도 초기버전의 설계이슈
   - 
   - 

3. ECMAScript의 표준화
   -
   -
   - 표준화에 실패함... 일치연산자로 보면 서로 다르다... 


# AI의 소개와 그 구성 요소

## 기계학습의 개념
### 기계학습 시스템 처리 과정
### 간단한 기계학습 예제

## AI의 주요 구성 요소 소개
### 모델(Model)
### 손실함수(Loss)
### 알고리즘(Algorithm)

## 모델평가
### 평가방법
### 오버피팅(Overfitting)



--------------

## 기계학습의 개념
- AI 의 구분
  - 인공지능(AI): 인간의 지능을 모방하여 문제 해결, 학습, 추론 등의 작업을 수행하는 시스템 및 기술
  - 기계학습(ML): 명시적인 프로그래밍 없이, 패턴을 학습하는 방법론
  - 딥러닝(DL): 뉴럴넷(인공신경망)을 모델로 기계학습 하는 것

### 기계학습 시스템 처리 과정(추론과정:Inference)
  1. 센싱: 카메라로 사진을 찍음(실제세계-> 디지털 세계)
   -> 바로 쓸수 없다. 밝기 어둡기가 모든 사진이 다달라서
   ->> 전처리 하기

  2. 전처리: 데이터에서 통계적 패턴을 잡기 쉽도록 하는 밑 작업(예: 밝기 값이 균등하도록)
   
  3. 특징 추출: 인식하고자 하는 목표와 연관이 이많은 특징들을 추출(자동차 탐지를 위해 사진에서 원형 패턴 추출)

  4. 분류: 기계 학습 모델을 통해 입력 득징을 인식 결과로 변환해 주느 ㄴ과정(자동차 인식)

 
### 간단한 기계학습 예제
1. 데이터 수집
   - 샘플
   - 훈련 집합(학습 데이터 셋), 테스트 집합(테스트 데이터 셋)
   - 고품질 데이터 확보가 매우 중요(양과 질)
   - 필기 숫자 예시
2. 특징 정의 및 추출
   1) 개별적인 화소를 특징 벡터화 하는 경우(Flatten)
   2) 각 축의 검은 화소의 비율

  - 분별력? : 특징공간에서의 샘플의 분포

3. 분류
   - 두 단계의 설계: 모델 선택(아키텍쳐 선택)과 학습(Learning) : 적당하게 잘 데이터를 골라야함.
   - 차원에 따라 : 결정 직선(곡선), 결정 평면(곡면), 결정 초평면(초곡면)
- 

4. 평가
   - 평가 데이터: 학습셋에서 학습 후, 테스트 셋에서 평가
   - 성능 평가 기준: 오류율, 인식률 등
   - 기계학습의 궁극적목표: 과적합을 피하자!

- 세부절차들은 모두 수학적(Software)으로 모델링 되어 있음.
  - AI는 수학을 많이 사용: 선형대수, 미분, 최적화
  - 본 강의에서는 일단 수학은 최소화
  - AI Ninja가 되고 싶다면?
    - Part1, Mathmatics for Machine Learning by Marc Peter, 2020(Free PDF)
    - 오일석, 기계학습, 한빛 아카데미, 2017 (패턴 인식, 2023)

## AI의 주요 구성 요소 소개
- 최근 AI는 대부분 딥러닝을 의미
  - 딥러닝 = 딥뉴럴넷
    - 전통적 기계 학습 단계 : 입력 -> 전처리-> 특징 추출-> 분류 -> 결과
    - 딥러닝 기반 학습 단계 : 입력 -> 딥뉴럴넷(특징 추출, 분류) -> 결과(End-to-end 학습)
  - 전동적 기계 학습
  - 딥러닝 기반 학습 

- 딥러닝의 주요 구성 요소
  - 모델: 입력 데이터를 우리가 원하는 출력을 변환해주는 함수
  - 손실함수: 모델의 출력을 통해 모델이 잘하는지 못하는지 판단해 수치화해주는 함수
  - 데이터: 모델이 학습할 데이터
  - 알고리즘: Loss를 줄여주기 위해 모델(파라미터)를 업데이터하는 방법

- AI 디자인 요소의 4(3)가지
  Model, Loss, Data(Loss, Data는 알고리즘)



### 모델(Model)
: 어떤 함수.
: Classifier: 입력 영상을 카테고리(클래스)로 매핑해주는 함수 f(.)

: 모델은 선형모델과 비선형 모델로 나눌수 있다.

: 선형모델
  - 단층 레이어 신경망
    : 뉴련이 신호를 전달하는 방식에 착안하여 제안된 초기 인공 신경망
    : 다수의 신호를 입력으로 받아 "선형 결합"으로 구성된 연산을 거친 후 하나의 결과를 내보내는 알고리즘.

    - 생물학적 뉴런 vs 인공신경망 뉴런
    : 뉴런에서 온 축색(입력), 수상돌기(가중치), 세포체(가중치의 합)
    , 출력, 활성화 함수(-> 비선형적인 부분)
    전체: (선형식)

    : 역치

  - 단층 레이어 신경망
  : 입력 데이터 -> 입력레이어 -> 출력 레이어 -> 예측 결과

  - 선형결합을 하는 것을 행렬곱으로 생각할 수 있다.
    C = AB
  - 행렬의 곱과 합으로 구성된 연산
    D = AB + C(AB + C 여기까지를 선형식이라고 함.)

  - 행렬의 곱셈의 예시 
    :  i = ae + bf + cg + dh
    =>> 각층에서 이루어지는 연산으 Y = XW +B로 표현
    (벡터의 내적으로 표현이 된다. )

  - 선형모델의 구성
    : 모델을 통해 예측하고자 하는 결과 y
    : 모델을 구성하는 가중치 W(파라미터)
    : 모델의 입력이 되는 데이터 x
      y = W^t x + b
      W^t는 가중치
      x는 입력데이터 고양이
      b는 맞춰주기위한 상수
      y는 고양이라는 예측결과

==>> 선형모델을 쓰는 경우, 이렇게 데이터를 찾아서 구성하면 됨.

### 손실함수(Loss)
: 학습 할 모델이 잘하고 있는지를 판단해주는 것.

: 모델의 출력값과 실제 데이터의 정답 사이의 오차를 계산하는 함수
  ex)모델이 2.2의 값을 예측 했는데 실제 정답이 2.0 이었다면, 두값의 차이인 0.2를 오차라고 
  정의
: AI모델을 학습한다는 것은 주어진 데이터에 대한 정답에 근사한 예측을 할 수 잇는 모델을 만드는 것
: 즉, 손실을 최대한 작은 값으로 줄이는 것이 AI학습 모델의 목표

손실함수의 예시
- 분류(Classification)
  Cross entropy

- 회귀(Regression)
  MSE(L2)
  MAE(L1)

- 기타. (skip)
  triplet
  KL Divergence
  Smooth L1


- 분류(Classification)
- : 주어진 데이터가 어떤 범주에 속하는지 판단하는 태스크
  
  : Logit과 확률값(probability)
    Logit: 표준화되지 않은 날 것 그대로의 모델 예측값
    확률: logit에 추가 연산(softmax)을 가하여 [0, 1]사이의 확률값으로 나타낸 예측값

  - Cross entropy
    : 분류에 쓰이는 가장 대표적인 손실 함수
    : 이진 분류
    : 다중 분류

- 회귀(Regression)
  : 범주가 아닌 연속적인 수치를 예측하는 태스크
    ex)사랑 키 예측, 9월의 제품 A 판매량 예측
  MSE(L2): 제곱의 에러를 평균낸것
  MAE(L1): 절댓갑 에러를 평규낸것

- 파이토치 손실함수( 파이선을 기반으로 함 )
  : 페이스북 ai연구팀이 개발한 오픈소스 딥러닝 프레임워크
  : 주로 신경망을 구축하고 훈련하는데 사용

- Gradient Descent(GD)
  : Loss function(손실 함수)의 최솟값을 찾아가기 위한 방법
  : 함수를 미분해서 기울기를 구하고, loss가 감소하는 방향으로 값을 업데이트
  : 함수에서 가장 낮은 값에 도달할 때까지 반복
  : 경사 하강법을 통해 weight가 업데이트 되는 과정

  : Gradient Descent Methods
    - Batch gradient descent: 데이터 전체에 대한 gradient를 계산하여 업데이트
    - Stochastic gradient descent: 데이터 샘플 1개에 대한 gradient를 계산하여 업데이트
    - Mini-batch gradient descent: 데이터 샘플 n개에 대하 gradientt를 계산하여 업데이트

- Batch Gradient Descent
  : 데이터 전체를 모두 본 다음. 각 데이터의 gradient를 모두 평균내서 업데이트 하는 방법
  : GD의 문제점: 데이터셋의 규모에 한계가 생김
  -> 데이터 샘플을 batch 단위 묶고, batch마다 gradient를 계산하고 업데이트 하는 방법

- Optimizer
- Step & epoch
  : Step: 신경망이 학습한 mini-batch 개수
  : Epoch : mini-batch를 모두 학습한 횟수(=전체 데이터 셋을 학습한 횟수)


- 기타. (skip)
  triplet
  KL Divergence
  Smooth L1
  


### 알고리즘(Algorithm)

## 모델평가
: 학습된 모델을 테스트 함으로써 일반화 능력을 측정하는 과정
: 평가를 통해 모델의 성능 개선 방향 결정

- 훈련, 테스트 셋 
  : 모델의 일반화 성능평가(= 과적합, Overfitting)를 위해 데이터 분할 필요

- Overfitting 
  : 학습된 모델이 새로운 데이터에 대한 일반화 성능이 떨어지는 현상
  : Train set 에서 높은 성능, test set에서 낮은 성능
  : 대표적인 Overfitting 치료법
  (Data augmentation, Regularization, Model design change, More training data)

- Reference
  - (영어) 머신러닝을 위한 수학(무료 PDF) https://mini-book.github.io/[Chap 2, 3, 5, 7, 8]
  - (영어) https://www.learnpytorch.io/
  - (영어) https://huggingface.co/learn

  - (한국어) 기계 학습, 오일석 / 패턴 인식, 오일석
  - (한국어) PyTorch 로 시작하는 딥러닝 입문 https://wikidocs.net/book/2788
  - (한국어) 공식 PyTorch 튜토리얼 https://tutorials.pytorch.kr/
  



### 평가방법
### 오버피팅(Overfitting)



# 2차시
간단한 뉴럴넷 모델

## 선형모델 및 MLP
### 행렬 곱셈과 비선형성
### Activation function 개념 소개

## 선형모델 Revisit
## Convolutinal Neural Network(CNN)
### Convolution, stridem, pooling
### Hierarchical representation

## 실습 PyTorch

------------------------

## 선형모델 및 MLP
- 선형 모델의 한계
  : 선입출력 사이의 선형 관계만 학습 가능
  : 즉, 직으로 구분되는 문제만 해결 가능

- 대표적으로 XOR분포는 선형모델로 오류 없이 구분 불가
- 

### 행렬 곱셈과 비선형성
- 비선형성
  - 복잡한 문제 해결
    : 현실의 데이터는 비선형적이므로, 복잡한 패턴을 학습하기 위해서는 비선형성을 도입해야함.
    : 비선형성 없이 단순한 선형모델로는 다차원 공간의 데이터나 복잡한 분포를 효과적으로 학습할 수 없음.

  - 대표적인 비선형모델로는 다층레이어 신경망이있다.
    : 딥러닝의 가장 기본적인 형태로, 여러 층의 노드가 연결된 구조를 가진 모델
    : 입력 레이어와 출력 레이어 사이에 '은닉층' 레이어 추가하여 2개 이상의 레이어를 쌓음
    : 여러개의 레이어를 쌓음으로서 더욱 복잡한 연산을 수행할 수 있음.

- Multi-Layer Perceptron(MLP)의 구성 - 행렬 곱셈
  : 행렬 곱셈은 신경망에서 각층의 노드(뉴런) 간 연결을 계산하는 기본연산
  Y = XW + B
  : 각 입력값에 가중치를 곱해 다음 층으로 전달
  : 모든 노드의 연결은 가중치라는 숫자로 표현됨.

- Multi-Layer Perceptron(MLP)의 구성
  : 입력층(Input Layer): 입력 데이터를 받는 층
  : 은닉층(Hidden Layer): 가충지와 활성화 함수를 통해 데이터를 처리.
  입력 데이터를 가공하여 중요한 특징(feature)을 추출하는 역할
  : 출력층(Output Layer): 최종결과를 출력하는 층

  : 입력데이터는 각 층을 거쳐 가중치와 "활성화 함수"에 의해 변환됨
  : 출력층에서는 예측 값이 계산됨.

- 선형 결합
  : 행렬의 곱은 선형 결합이므로 2번 이상의 행렬 곱 결과를 하나의 행렬로 나타낼 수 있다.
  : 선형 결합으로만 이루어진 연산은 아무리 연산을 반복해도 결국 선형 결합일 수 밖에 없다.= 선형적인 관계만을 학습 할 수 있음.
  : 활성화 함수가 없다면, 신경망은 단순히 행렬 곱셈과 덧셈만 수행하고, 이는 결국 선형관계로 이어짐








  

### Activation function 개념 소개

## 선형모델 Revisit
## Convolutinal Neural Network(CNN)
### Convolution, stridem, pooling
### Hierarchical representation

## 실습 PyTorch